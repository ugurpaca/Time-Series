{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Time Series Analysis: The Hidden Pattern in Your Data That's Costing You Millions\n",
        "\n",
        "*Part 1 of 8: Introduction to Time Series Analysis*\n",
        "\n",
        "---\n",
        "\n",
        "It's 3 AM, and Sarah, a senior data scientist at a major e-commerce company, is staring at her laptop screen. The quarterly revenue forecasts she submitted last week were off by 23%. The CFO wants answers. Her machine learning models\u2014the same ones that worked brilliantly for customer segmentation\u2014completely failed to predict holiday sales patterns.\n",
        "\n",
        "Sarah's mistake wasn't using bad data or poor algorithms. Her mistake was treating time series data like any other dataset.\n",
        "\n",
        "If you've ever wondered why your ML models break down when predicting stock prices, why your demand forecasting always misses the mark during peak seasons, or why that beautiful Random Forest can't predict tomorrow's temperature, you're facing the same challenge Sarah did: **time changes everything**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Fundamental Difference: Why Time Matters\n",
        "\n",
        "Imagine you're analyzing customer data. You have 10,000 customers, and you want to predict who will churn. Each customer is independent\u2014John's decision to leave doesn't directly affect Maria's decision. You can shuffle your rows, split them randomly into train and test sets, and your model will work fine.\n",
        "\n",
        "Now imagine you're analyzing stock prices. If you shuffle the rows, you've destroyed the most important information: the sequence. Tuesday's price doesn't just correlate with Monday's price\u2014it's *caused* by everything that happened up to Monday. The order is the insight.\n",
        "\n",
        "This is the essence of time series data: **observations are not independent; they're connected through time**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What Makes Data a Time Series?\n",
        "\n",
        "A time series is simply a sequence of data points indexed in time order. But not all temporal data is a time series in the analytical sense. Consider these examples:\n",
        "\n",
        "**True Time Series:**\n",
        "- Daily stock prices\n",
        "- Hourly temperature readings\n",
        "- Monthly sales figures\n",
        "- Minute-by-minute server CPU usage\n",
        "- Quarterly GDP growth\n",
        "\n",
        "**Temporal Data (but not time series):**\n",
        "- Customer purchase timestamps (events, not continuous measurements)\n",
        "- Transaction logs (discrete events)\n",
        "- User registration dates (one-time occurrences)\n",
        "\n",
        "The key distinction: time series data involves **regular measurements of the same phenomenon over time**, where the temporal ordering contains critical information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Real-World Impact: Three Stories\n",
        "\n",
        "### Story 1: The Retailer Who Forgot About Seasonality\n",
        "\n",
        "A major clothing retailer implemented a state-of-the-art neural network to predict inventory needs. The model was trained on two years of data and achieved impressive accuracy on the test set\u201495% R\u00b2 score.\n",
        "\n",
        "In January, they ordered inventory based on the model's predictions. By March, their warehouses were overflowing with winter coats nobody wanted, and they were desperately trying to source summer dresses that were out of stock.\n",
        "\n",
        "What went wrong? The model treated each month independently. It learned that \"high sales in December\" meant \"high sales next month,\" but it didn't understand that December's high sales were Christmas-driven, and January always sees a dramatic drop.\n",
        "\n",
        "**The lesson**: Time series have patterns that repeat\u2014seasonality, trends, cycles\u2014and ignoring them is expensive.\n",
        "\n",
        "### Story 2: The Startup That Learned About Stationarity\n",
        "\n",
        "A fintech startup was building a fraud detection system. Their data scientist noticed that transaction amounts were increasing over time (good news\u2014the business was growing). She built a model using the raw transaction amounts and deployed it.\n",
        "\n",
        "Three months later, the model was flagging legitimate transactions as fraud at an alarming rate. Customer complaints skyrocketed.\n",
        "\n",
        "The problem? As the business grew, typical transaction sizes increased. The model learned that \"$5,000 transactions are normal\" based on historical data. But by month three, $8,000 transactions were normal. The model was comparing apples (current data) to oranges (past data).\n",
        "\n",
        "**The lesson**: Time series properties can change over time. The statistical properties you observe today might not hold tomorrow.\n",
        "\n",
        "### Story 3: The Energy Company That Predicted the Unpredictable\n",
        "\n",
        "An energy company needed to predict electricity demand to optimize power generation. Too much generation wastes money; too little causes blackouts.\n",
        "\n",
        "Their first model used a simple approach: \"tomorrow's demand will be similar to today's.\" It worked reasonably well\u2014until it didn't. During a sudden cold snap, demand spiked 40% higher than predicted. Blackouts cost the company $50 million in a single week.\n",
        "\n",
        "They brought in a time series expert who built a model incorporating:\n",
        "- Temperature forecasts (external variable)\n",
        "- Day of week patterns (weekly seasonality)\n",
        "- Hour of day patterns (daily seasonality)\n",
        "- Trend in baseline consumption (gradual changes)\n",
        "- Special events (holidays, major sports games)\n",
        "\n",
        "The new model wasn't perfect, but it reduced prediction errors by 60% and saved millions in avoided blackouts and optimized generation.\n",
        "\n",
        "**The lesson**: Time series analysis isn't just about past values\u2014it's about understanding the complex interplay of multiple temporal patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Four Fundamental Components\n",
        "\n",
        "Every time series can be decomposed into four components. Understanding these is crucial for both analysis and forecasting.\n",
        "\n",
        "![The Four Fundamental Components](four_components.png)\n",
        "*Figure 1: The four fundamental components that make up any time series. Notice how each component has distinct characteristics and behavior patterns.*\n",
        "\n",
        "### 1. Trend (T)\n",
        "\n",
        "The long-term movement in the data. Is it generally going up, down, or staying flat over time?\n",
        "\n",
        "**Example**: E-commerce sales have been growing at 15% annually for five years. That's your trend.\n",
        "\n",
        "Think of trend as the \"big picture direction\"\u2014what happens when you zoom out and ignore the noise.\n",
        "\n",
        "### 2. Seasonality (S)\n",
        "\n",
        "Regular, repeating patterns at fixed intervals. These can be:\n",
        "- **Daily**: Rush hour traffic peaks at 8 AM and 5 PM\n",
        "- **Weekly**: Restaurant traffic surges on weekends\n",
        "- **Monthly**: Utility bills spike in summer (AC) and winter (heating)\n",
        "- **Quarterly**: Retail sales boom in Q4 (holidays)\n",
        "- **Yearly**: Ice cream sales peak in summer\n",
        "\n",
        "Seasonality is predictable and repeats with the same magnitude and timing.\n",
        "\n",
        "### 3. Cyclical (C)\n",
        "\n",
        "Longer-term fluctuations that don't have a fixed period. These are often tied to economic or business cycles.\n",
        "\n",
        "**Example**: Real estate markets have boom-bust cycles that last 7-10 years, but they're not exactly regular like seasons.\n",
        "\n",
        "The key difference from seasonality: cyclical patterns don't have a fixed frequency or amplitude.\n",
        "\n",
        "### 4. Residual/Irregular (R)\n",
        "\n",
        "Random noise and one-off events that can't be explained by trend, seasonality, or cycles.\n",
        "\n",
        "**Example**: A spike in umbrella sales due to an unexpected rainstorm, a drop in traffic due to a sudden road closure.\n",
        "\n",
        "This is the \"everything else\" component\u2014the truly unpredictable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Install Required Packages\n",
        "\n",
        "First, let's install the necessary libraries for time series analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (uncomment if needed)\n",
        "# !pip install pandas numpy matplotlib seaborn statsmodels scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Decomposition: Seeing the Invisible\n",
        "\n",
        "Let's look at a real example using Python. We'll analyze airline passenger data\u2014a classic time series that beautifully demonstrates all components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (15, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load classic airline passenger dataset\n",
        "# Monthly totals of international airline passengers, 1949-1960\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
        "df = pd.read_csv(url, parse_dates=['Month'], index_col='Month')\n",
        "df.columns = ['Passengers']\n",
        "\n",
        "# Quick look at the data\n",
        "print(df.head())\n",
        "print(f\"\\nData shape: {df.shape}\")\n",
        "print(f\"Date range: {df.index.min()} to {df.index.max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize raw data\n",
        "plt.figure(figsize=(15, 4))\n",
        "plt.plot(df.index, df['Passengers'], linewidth=2)\n",
        "plt.title('Airline Passengers Over Time', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Year', fontsize=12)\n",
        "plt.ylabel('Number of Passengers (thousands)', fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When you plot this data, you immediately see:\n",
        "1. **Clear upward trend**: Air travel is growing\n",
        "2. **Regular spikes**: Summer peaks every year (seasonality)\n",
        "3. **Increasing variance**: The seasonal swings get bigger as the trend increases\n",
        "\n",
        "Now let's decompose it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform seasonal decomposition\n",
        "# Using multiplicative model because variance increases with trend\n",
        "decomposition = seasonal_decompose(df['Passengers'], \n",
        "                                   model='multiplicative', \n",
        "                                   period=12)  # 12 months = 1 year\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(4, 1, figsize=(15, 12))\n",
        "\n",
        "# Original\n",
        "df['Passengers'].plot(ax=axes[0], title='Original Time Series', \n",
        "                       color='#2E86AB', linewidth=2)\n",
        "axes[0].set_ylabel('Passengers')\n",
        "\n",
        "# Trend\n",
        "decomposition.trend.plot(ax=axes[1], title='Trend Component', \n",
        "                         color='#A23B72', linewidth=2)\n",
        "axes[1].set_ylabel('Trend')\n",
        "\n",
        "# Seasonal\n",
        "decomposition.seasonal.plot(ax=axes[2], title='Seasonal Component', \n",
        "                             color='#F18F01', linewidth=2)\n",
        "axes[2].set_ylabel('Seasonality')\n",
        "\n",
        "# Residual\n",
        "decomposition.resid.plot(ax=axes[3], title='Residual Component', \n",
        "                         color='#C73E1D', linewidth=1, alpha=0.7)\n",
        "axes[3].set_ylabel('Residuals')\n",
        "axes[3].axhline(y=1, color='black', linestyle='--', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical summary of components\n",
        "print(\"\\nComponent Statistics:\")\n",
        "print(f\"Trend range: {decomposition.trend.min():.2f} to {decomposition.trend.max():.2f}\")\n",
        "print(f\"Seasonal range: {decomposition.seasonal.min():.2f} to {decomposition.seasonal.max():.2f}\")\n",
        "print(f\"Residual std: {decomposition.resid.std():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What This Reveals\n",
        "\n",
        "Looking at the decomposition:\n",
        "\n",
        "**Trend**: Smooth upward curve showing ~4x growth over 12 years. This tells you the airline industry was booming in the 1950s.\n",
        "\n",
        "**Seasonal**: Regular pattern repeating every 12 months. Notice:\n",
        "- Peaks in July-August (summer vacation)\n",
        "- Troughs in November-February (winter, post-holiday)\n",
        "- Same pattern every year\n",
        "\n",
        "**Residual**: Mostly small fluctuations around the baseline, with occasional spikes (perhaps unusual weather, special events, or data collection issues)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additive vs. Multiplicative Models\n",
        "\n",
        "Notice we used `model='multiplicative'` in our decomposition. This is a crucial choice:\n",
        "\n",
        "![Additive vs Multiplicative Models](additive_vs_multiplicative.png)\n",
        "*Figure 2: Comparison of additive and multiplicative decomposition models. In additive models, seasonal variations remain constant (left). In multiplicative models, seasonal variations grow proportionally with the trend (right).*\n",
        "\n",
        "**Additive Model**: `Y(t) = T(t) + S(t) + R(t)`\n",
        "- Use when seasonal variations are roughly constant over time\n",
        "- Example: Daily temperature in a stable climate\n",
        "\n",
        "**Multiplicative Model**: `Y(t) = T(t) \u00d7 S(t) \u00d7 R(t)`\n",
        "- Use when seasonal variations grow/shrink with the trend\n",
        "- Example: Our airline data\u2014summer peaks get bigger as the trend increases\n",
        "\n",
        "Here's how to decide:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visual test: Plot the data on different scales\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 4))\n",
        "\n",
        "# Linear scale\n",
        "axes[0].plot(df.index, df['Passengers'])\n",
        "axes[0].set_title('Linear Scale - See Growing Variance')\n",
        "axes[0].set_ylabel('Passengers')\n",
        "\n",
        "# Log scale\n",
        "axes[1].plot(df.index, df['Passengers'])\n",
        "axes[1].set_yscale('log')\n",
        "axes[1].set_title('Log Scale - Variance Stabilized?')\n",
        "axes[1].set_ylabel('Passengers (log scale)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the log-transformed data shows constant variance, use multiplicative. If the original data shows constant variance, use additive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Your First Time Series Analysis Checklist\n",
        "\n",
        "Before you start building models, ask yourself:\n",
        "\n",
        "### 1. **Is this really a time series problem?**\n",
        "   - Do I care about the temporal ordering?\n",
        "   - Am I trying to forecast future values?\n",
        "   - Are there temporal dependencies in my data?\n",
        "\n",
        "### 2. **What patterns exist?**\n",
        "   - Is there a trend? (Plot it and look)\n",
        "   - Is there seasonality? (Look for repeating patterns)\n",
        "   - At what frequency? (Daily, weekly, monthly, yearly?)\n",
        "\n",
        "### 3. **Is it stationary?**\n",
        "   - Do the statistical properties change over time?\n",
        "   - Does the mean wander?\n",
        "   - Does the variance change?\n",
        "   \n",
        "   (We'll dive deep into stationarity in Part 3)\n",
        "\n",
        "### 4. **What's my forecast horizon?**\n",
        "   - Next hour? Next month? Next year?\n",
        "   - Short-term forecasts can use different methods than long-term\n",
        "\n",
        "### 5. **What external factors matter?**\n",
        "   - Weather, holidays, promotions, economic indicators?\n",
        "   - These become \"exogenous variables\" in your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A Quick Win: Your First Forecast\n",
        "\n",
        "Let's end with something practical. Here's a simple but effective forecasting approach you can use immediately:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "\n",
        "# Split data: train on first 10 years, test on last 2 years\n",
        "train_size = int(len(df) * 0.83)  # ~10 years\n",
        "train = df[:train_size]\n",
        "test = df[train_size:]\n",
        "\n",
        "# Fit Holt-Winters model\n",
        "# This automatically handles trend and seasonality\n",
        "model = ExponentialSmoothing(\n",
        "    train['Passengers'],\n",
        "    seasonal_periods=12,\n",
        "    trend='add',\n",
        "    seasonal='mul'\n",
        ")\n",
        "fitted_model = model.fit()\n",
        "\n",
        "# Forecast\n",
        "forecast = fitted_model.forecast(steps=len(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(train.index, train['Passengers'], label='Training Data', linewidth=2)\n",
        "plt.plot(test.index, test['Passengers'], label='Actual', linewidth=2)\n",
        "plt.plot(test.index, forecast, label='Forecast', linewidth=2, linestyle='--')\n",
        "plt.title('Airline Passengers: Forecast vs Actual', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Passengers (thousands)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate accuracy\n",
        "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
        "\n",
        "mape = mean_absolute_percentage_error(test['Passengers'], forecast)\n",
        "rmse = np.sqrt(mean_squared_error(test['Passengers'], forecast))\n",
        "\n",
        "print(f\"\\nForecast Accuracy:\")\n",
        "print(f\"MAPE: {mape*100:.2f}%\")\n",
        "print(f\"RMSE: {rmse:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With just a few lines of code, you've built a model that:\n",
        "- Captures the trend\n",
        "- Accounts for seasonality\n",
        "- Produces reasonable forecasts\n",
        "\n",
        "This is your baseline. In the coming articles, we'll learn when this approach works, when it fails, and how to build more sophisticated models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What's Next\n",
        "\n",
        "Sarah, our data scientist from the beginning, eventually figured it out. She learned to:\n",
        "- Decompose her sales data to understand seasonal patterns\n",
        "- Use different models for different product categories\n",
        "- Incorporate external variables (holidays, promotions, weather)\n",
        "- Validate her models properly using time-aware cross-validation\n",
        "\n",
        "Her forecasts improved from 23% error to 8% error. The CFO was happy. Sarah got promoted.\n",
        "\n",
        "The difference wasn't just better algorithms\u2014it was understanding that time series data requires a fundamentally different approach.\n",
        "\n",
        "In **Part 2**, we'll dive deeper into decomposition techniques, explore STL (Seasonal and Trend decomposition using Loess), and learn how to identify the right decomposition strategy for your data.\n",
        "\n",
        "In **Part 3**, we'll tackle the concept that makes or breaks most time series models: **stationarity**. You'll learn why your model might be learning the wrong patterns and how to fix it.\n",
        "\n",
        "For now, take any time series dataset you're working with and:\n",
        "1. Plot it\n",
        "2. Decompose it\n",
        "3. Ask: What patterns do I see?\n",
        "\n",
        "The answers will surprise you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "- **Time series data is fundamentally different**: observations are connected through time, not independent\n",
        "- **Four components matter**: trend, seasonality, cycles, and residuals\n",
        "- **Decomposition reveals hidden patterns**: what looks like noise might be seasonal variation\n",
        "- **Choose the right model type**: additive for constant variance, multiplicative for growing variance\n",
        "- **Start simple**: even basic methods like Holt-Winters can be surprisingly effective\n",
        "\n",
        "## Resources & Further Reading\n",
        "\n",
        "- **Dataset used**: [Airline Passengers Dataset](https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv)\n",
        "- **Libraries**: statsmodels, pandas, matplotlib, seaborn\n",
        "- **Next in series**: Part 2 - Advanced Decomposition Techniques"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}